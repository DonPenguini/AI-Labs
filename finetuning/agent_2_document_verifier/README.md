# Agent 2: Document Verifier with Graph RAG

## Overview

Agent 2 verifies that Scientific Simulation Documents (SSD) generated by Agent 1 accurately represent the source document or user query. It checks whether equations, parameters, assumptions, and constraints from the source are correctly extracted and present in the SSD, without hallucinations or missing elements.

## Purpose

This agent focuses on **source fidelity** rather than domain correctness. It answers:
- Are all equations from the source document present in the SSD?
- Are parameters correctly identified with their mentioned constraints?
- Are assumptions accurately captured?
- Are there any hallucinated elements not in the source?
- Are there missing elements that should be included?

## Features

- **Document Analysis**: Extracts equations, parameters, assumptions, and constraints from source text
- **Semantic Verification**: Uses sentence embeddings to match source elements with SSD elements  
- **Pattern Matching**: Regex patterns for equations, constraints, and assumptions
- **Fidelity Scoring**: Provides accuracy scores for equations, parameters, assumptions, constraints
- **Missing/Extra Detection**: Identifies elements missing from SSD or added without source basis
- **Multi-domain Support**: Physics, Electrical Engineering, Mechanical Engineering, Biology

## Verification Approach

### 1. Source Document Analysis

The verifier extracts key elements from the source:
- **Equations**: Mathematical expressions using regex patterns
- **Parameters**: Variables mentioned with values or units
- **Assumptions**: Sentences containing assumption keywords (assume, ignore, negligible, etc.)
- **Constraints**: Sentences containing constraint keywords (must, should, range, limit, etc.)

### 2. SSD Element Extraction

Extracts corresponding elements from the generated SSD:
- Equations from `equations` field
- Parameters from `parameters` field
- Assumptions from `assumptions` field
- Constraints from `constraints` field

### 3. Semantic Matching

Uses sentence-transformers to compare source and SSD elements:
- Encodes both source and SSD elements as embeddings
- Computes cosine similarity
- Matches elements above threshold (0.6-0.7)
- Identifies missing and extra elements

### 4. Fidelity Scoring

Provides multiple accuracy metrics:
- **Equation Accuracy**: Coverage of source equations in SSD
- **Parameter Completeness**: Percentage of source parameters captured
- **Assumption Completeness**: Coverage of source assumptions
- **Constraint Accuracy**: Coverage of source constraints
- **Overall Fidelity**: Weighted combination of above scores

## Usage

### Training

```bash
cd finetuning/agent_2_document_verifier

# Basic training
python train.py

# With custom parameters
FINETUNE_DATA=../../training_dataset/agent_2_document_verifier/model2_samples.jsonl \
FINETUNE_MODEL=unsloth/Qwen2.5-Coder-7B-Instruct \
FINETUNE_EPOCHS=3 \
FINETUNE_LR=2e-4 \
FINETUNE_BATCH_SIZE=2 \
FINETUNE_GRAD_ACCUM=8 \
python train.py
```

### Running Verification

```bash
# Verify batch of source document + SSD pairs
python run_verification.py \
  --model outputs_agent2_lora/final_model \
  --input verification_pairs.jsonl \
  --output verification_results.jsonl \
  --embedding-model all-MiniLM-L6-v2
```

Input JSONL format:
```json
{
  "source_document": "Create a simulation for projectile motion...",
  "ssd_document": {"simulation_name": "Projectile Motion", ...}
}
```

### Programmatic Usage

```python
from graph_rag import DocumentVerifierRAG

# Initialize Document Verifier RAG
verifier = DocumentVerifierRAG(
    embedding_model="all-MiniLM-L6-v2"
)

# Analyze source document
source = "A ball is launched with speed v0..."
analysis = verifier.analyze_source_document(source)
print(f"Extracted equations: {analysis.extracted_equations}")
print(f"Extracted parameters: {analysis.extracted_parameters}")

# Verify an SSD document
ssd_document = {
    "simulation_name": "Projectile Motion",
    "domain": "Electrical Engineering",
    "equations": [
        {"expression": "vc(t) = Vin*(1 - exp(-t/(R*C)))"}
    ],
    "parameters": [
        {"symbol": "R", "unit": "ohm", "range": [10, 1e7]},
        {"symbol": "C", "unit": "F", "range": [1e-9, 0.1]},
        {"symbol": "Vin", "unit": "V", "range": [0, 50]}
    ]
}

# Retrieve relevant domain knowledge
knowledge = rag.retrieve_domain_knowledge(ssd_document, top_k=5)
print(f"Retrieved {len(knowledge.equations)} equations")
print(f"Confidence: {knowledge.confidence_score}")

# Verify equations
eq_verification = rag.verify_equations(ssd_document, knowledge)
print(f"Equation valid: {eq_verification['valid']}")
print(f"Issues: {eq_verification['issues']}")

# Verify parameters
param_verification = rag.verify_parameters(ssd_document, knowledge)
print(f"Parameters valid: {param_verification['valid']}")
```

## Supported Domains

### Physics
- Projectile motion
- Simple harmonic motion (pendulum)
- Kinematics
- Dynamics

### Electrical Engineering
- RC circuits
- RL circuits
- Ohm's Law
- Power circuits

### Mechanical Engineering
- Heat conduction (Fourier's Law)
- Thermal stress
- Fluid dynamics (basic)

### Biology
- Logistic population growth
- SIR epidemic models
- Predator-prey systems (Lotka-Volterra)

## Verification Output Format

```json
{
    "status": "valid|needs_correction",
    "issues": [
        {
            "type": "parameter_range|equation_unknown|constraint_missing",
            "severity": "error|warning|info",
            "field": "parameters[0].range",
            "message": "Description of the issue",
            "suggestion": "How to fix it"
        }
    ],
    "corrections": [
        {
            "field": "parameters[0].range",
            "old_value": [-50, 50],
            "new_value": [0, 50],
            "reason": "Voltage should be positive"
        }
    ],
    "confidence": 0.95,
    "summary": "Overall verification summary"
}
```

## Graph Management

### Viewing Graph Contents

```python
from graph_rag import GraphRAG

rag = GraphRAG()

# Print all equations
for node_id in rag.graph.nodes():
    node = rag.graph.nodes[node_id]
    if node.get('type') == 'equation':
        print(f"{node['name']} ({node['domain']})")
        print(f"  Equations: {node['equations']}")
        print(f"  Parameters: {node['parameters']}")
        print()
```

### Saving/Loading Graphs

```python
# Save graph to file
rag.save_graph("my_knowledge_graph.json")

# Load graph from file
rag2 = GraphRAG(graph_data_path="my_knowledge_graph.json")
```

### Adding Custom Knowledge

```python
# Add new equation to graph
rag.graph.add_node(
    "eq_custom",
    type="equation",
    domain="Physics",
    name="Custom Formula",
    equations=["formula1", "formula2"],
    parameters=["param1", "param2"],
    constraints=["param1 > 0"],
    related_concepts=["concept1"]
)

# Save updated graph
rag.save_graph("updated_graph.json")
```

## Training Data Format

Each training sample in `model2_samples.jsonl`:

```json
{
    "instruction": "Verify that the generated SSD accurately represents the source document...",
    "source_document": "Create a simulation for projectile motion...",
    "ssd_output": {
        "simulation_name": "...",
        "domain": "...",
        "equations": [...],
        "parameters": [...]
    },
    "verification_output": {
        "equation_accuracy": 1.0,
        "parameter_completeness": 1.0,
        "assumption_completeness": 1.0,
        "constraint_accuracy": 0.95,
        "missing_elements": [],
        "extra_elements": [],
        "overall_fidelity": 0.99,
        "summary": "Excellent fidelity..."
    }
}
```

## Extraction Patterns

### Equations
- Function form: `f(x) = ...`
- Assignment: `x = ...`
- Derivatives: `dx/dt = ...`, `∂x/∂t = ...`
- Mathematical expressions with operators

### Assumptions
Keywords: assume, assuming, ignore, negligible, ideal, constant, uniform, steady

### Constraints  
Keywords: must, should, range, limit, greater than, less than, between, when, if

## Testing

Run the Document Verifier RAG standalone:

```bash
python graph_rag.py
```

This will test:
- Source document analysis
- Equation extraction
- Parameter identification
- Semantic similarity matching
- Fidelity scoring

## Future Enhancements

- [ ] Symbolic math verification using SymPy
- [ ] Better equation normalization (e.g., `x = y + z` vs `z = x - y`)
- [ ] Unit consistency checking
- [ ] Detect paraphrased assumptions
- [ ] Support for multi-step derivations
- [ ] LaTeX equation parsing
4. Create training samples for the new domain
5. Retrain Agent 2

## References

- Graph-based Knowledge Representation
- Semantic Search with Sentence Transformers
- Scientific Equation Verification
- Domain-Specific Language Models
